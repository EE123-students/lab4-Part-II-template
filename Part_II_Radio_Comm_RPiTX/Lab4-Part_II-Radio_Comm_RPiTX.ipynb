{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 Part II: Radio Communication via an RPiTX and the SDR\n",
    "\n",
    "This is an alpha version of the lab, meant for those who have issues with their radio or audio interface, or have not gotten a radio for a number of reasons. I developed this lab over Spring break 2020, being sheltered in place due to the COVID-19 virus epidemic. \n",
    "\n",
    "Again, this is an *alpha* version and has not been debugged almost at all -- so things may not work, break or vary for different people. Please bear that in mind and work with us to perfect this lab.\n",
    "\n",
    "In this lab you will receive RF signals using the RTL-SDR, and transmit signals using the Raspberry Pi itself. This lab heavily uses several amazing open source projects, which I'm grateful for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning the Raspberry Pi into a transmitter\n",
    "The original work for this hack was created by the Imperial College Robotic Society. It was later extended by Oliver Mattos and Oskar Weigle to the PiFM code, and finally turned into a full-fledged package called RPiTX by Evariste Courjad (F50EO). \n",
    "\n",
    "The hack uses the hardware on the Raspberry Pi that is actually meant to generate variable frequencies -- computer controlled clock signals on the GPIO pins. By cleverly using DMA and inputting different frequencies at different times, the software can generate a frequency modulated (FM) signal out of GPIO 4 (pin 7) of the Raspberry Pi.\n",
    "Any freqency between 0 and 250 MHz can be set, and because the carrier signal is a square wave, the signal produced has very strong harmonics. By using the harmonics it is possible to generate carriers even at 1 GHz. \n",
    "\n",
    "When connected to an antenna or a wire, this \"radio\" will result in illegal emmissions (harmonics). But without any wire or antenna connected to the pins, the amount of power emmitted is small and ranges over a few feet. This will enable us to use this approach for this lab, without implementing a bandpass filter. \n",
    "\n",
    "This code, along with RTL-SDR and CSDR, are the basis for making this lab work. \n",
    "\n",
    "### References:\n",
    "\n",
    "* [ICRobotics](http://www.icrobotics.co.uk/wiki/index.php/Turning_the_Raspberry_Pi_Into_an_FM_Transmitter)\n",
    "* [PiFM github](https://github.com/rm-hull/pifm)\n",
    "* [RPiTX github](https://github.com/F5OEO/rpitx)\n",
    "* [librtlsdr](https://github.com/librtlsdr/librtlsdr)\n",
    "* [CSDR](https://github.com/ha7ilm/csdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Setup\n",
    "\n",
    "For this lab, you will need **your Raspberry Pi, speaker, SDR and antenna.**\n",
    "\n",
    "At various points in the lab, you may need to move your antenna around to adjust performance. Keep in mind that you do not want the antenna very far away from the SDR due to the low power output, and you do not want the antenna too close to the other equipment due to interference.\n",
    "\n",
    "Your setup should look like the following figure.\n",
    "\n",
    "<center><img src=\"./pinout.jpg\" alt=\"gsm\" style=\"width: 400px;\"/></center>\n",
    "<center>Figure 1: Raspberry Pi pinout</center>\n",
    "\n",
    "<center><img src=\"./rpitx-setup.jpg\" alt=\"gsm\" style=\"width: 400px;\"/></center>\n",
    "<center>Figure 2: Equipment setup</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Radio class (wrapping rtlsdr and rpitx in python)\n",
    "\n",
    "The way I implemented the \"radio\" is by calling shell commands that use rtl_fm (a software for demodulating FM radio signal using rtlsdr), rpitx, and CSDR. To pipe the audio into and out of python, we leverage the loopback audio device, which is a virtual device enabling piping of audio between applications. \n",
    "\n",
    "In order for this to work, you need to have snd_aloop linux kernel module loaded. You also need to be able to run sudo without password entry. \n",
    "\n",
    "Make sure you do the following: open a terminal on the Pi through SSH, bluetooth, or serial connection. \n",
    "\n",
    "1. In the terminal, type:\n",
    "~~~~\n",
    "sudo visudo\n",
    "~~~~\n",
    "\n",
    "Append the following line to the end of the file, and save:\n",
    "~~~~\n",
    "pi ALL=(ALL) NOPASSWD:ALL\n",
    "~~~~\n",
    "\n",
    "You should now be able to run `sudo` without a password. \n",
    "\n",
    "2. In the terminal, type:\n",
    "~~~~\n",
    "sudo modprobe snd_aloop\n",
    "~~~~\n",
    "\n",
    "This will load the loopback audio module. **NOTE: Step 2 is not persistent, and you will need to do this every time you boot the Pi.** \n",
    "\n",
    "Two important audio devices that are created are: `plughw:CARD=Loopback,DEV=0`,  and `plughw:CARD=Loopback,DEV=1`. These are the loopback devices. We will use `DEV=1` from python and `DEV=0` from outside.\n",
    "\n",
    "The following code should show if the Loopback module was loaded and the devices are set. You should see the output\n",
    "~~~~\n",
    "plughw:CARD=Loopback,DEV=0\n",
    "plughw:CARD=Loopback,DEV=1\n",
    "~~~~\n",
    "if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo modprobe snd_aloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code should show if the Loopback module was loaded and the devices are set.\n",
    "\n",
    "! aplay -L | grep plughw:CARD=Loopback,DEV="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Because of some HW interference issues, the rpitx provided in your installation will have hardware collisions with the sound interface. To minimize this, we patched rpitx and provided you with an executable. You need to copy that executable to /usr/bin/ by:\n",
    "\n",
    "```\n",
    "sudo cp rpitx /usr/bin\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp rpitx /usr/bin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Radio class, spectrogram, and spectrum display from 'lab4_2_utils.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab4_2_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions and libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio, threading, time, sys, serial\n",
    "import queue as Queue\n",
    "from numpy import pi, sin, zeros, r_\n",
    "from scipy import signal\n",
    "from rtlsdr import RtlSdr\n",
    "import sounddevice as sd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up alsamixer volumes for the Raspberry Pi\n",
    "\n",
    "!amixer -c 1 -- sset 'Capture Mux' 'LINE_IN'\n",
    "!amixer -c 1 -- sset Lineout playback unmute\n",
    "!amixer -c 1 -- sset Lineout playback 50%,50%\n",
    "!amixer -c 1 -- sset Mic capture 66%\n",
    "!amixer -c 1 -- sset Mic playback 66%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing audio I/O and radio receive\n",
    "\n",
    "### Testing the audio:\n",
    "\n",
    "The first test/example would be to see if we can capture audio from the radio and play it on the Raspberry Pi.\n",
    "\n",
    "An important feature in this task is that **you will have a method to check if the incoming signal is being clipped. Remember the settings for which the signal maximum is 0.6. This would be VERY useful in the communications part of the lab.** This is less of a problem for the sdr + rpitx setup than the audio inteface and the Baofeng, but still...\n",
    "\n",
    "Another important caveat: due to intefering devices within the Pi, it is not possible to transmit with rpitx and *also* play sound using any of the sound interfaces. Any attempt to do so will require a restart. Don't say I did not warn you!!!\n",
    "\n",
    "Let's start a radio object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Radio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the frequency to a local FM station. At Berkeley, it would be 94.1 MHz, or 94100 kHz. We will also route the radio output directly to the Fe-Pi audio. **Make sure your speaker is connected to the RX/Speaker green connector.** Make sure the SDR gain is set appropriately (gain of 36 is reasonable).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.audiodev_out = \"plughw:CARD=Audio,DEV=0\"\n",
    "R.freq_rx = 94100.0\n",
    "R.sdr_gain = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to run the wide-band FM receiver. After running, you will see the shell command line that was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.WBFMrx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the device we run R.stoprx(), or R.close(). The latter will also kill any transmitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R.stoprx()\n",
    "R.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to run the radio while piping the audio to the loopback audio device, so we can read it within python. We will first need to set the audio. We will be using the SoundDevice python audio library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will list the audio devices on your pi. You should see:\n",
    "```\n",
    " 0 bcm2835 ALSA: - (hw:0,0), ALSA (0 in, 2 out)\n",
    "  1 bcm2835 ALSA: IEC958/HDMI (hw:0,1), ALSA (0 in, 2 out)\n",
    "  2 Fe-Pi Audio: - (hw:1,0), ALSA (2 in, 2 out)\n",
    "  3 Loopback: PCM (hw:2,0), ALSA (32 in, 32 out)\n",
    "  4 Loopback: PCM (hw:2,1), ALSA (32 in, 32 out)\n",
    "  5 sysdefault, ALSA (0 in, 128 out)\n",
    "  6 dmix, ALSA (0 in, 2 out)\n",
    "* 7 default, ALSA (2 in, 2 out)\n",
    "```\n",
    "You may see something slightly different than the above. \n",
    "But, if you don't see a loopback, you need to repeat the `sudo modprobe snd_aloop`. If you don't see the Fe-Pi Audio device, then it means that something is off. Try rebooting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.query_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually set the audio device numbers. \n",
    "\n",
    "builtin_idx = 2 #should be the Fe-Pi Audio\n",
    "\n",
    "loop1_idx  = 4 #should be Loopback: PCM (hw:2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builtin_idx = 2 # should be the Fe-Pi Audio\n",
    "loop1_idx = 4 # should be Loopback: PCM (hw:2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also set up default of 1 channel and sampling rate of 48 kHz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default sample rate and number of channels. \n",
    "sd.default.samplerate = 48000\n",
    "sd.default.channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows how to read data from a device, using a callback function and a stream. The callback function in this case is simple: it copies the input data stream (loop1) to an output data stream (builtin), so we can hear what is being streamed by the radio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this callback function will play captured data \n",
    "# it will be called by the sounddevice stream and run in a different thread\n",
    "\n",
    "def replay_callback(indata, outdata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    outdata[:] = indata  # the [:] is important so data is copied not referenced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a new radio. Since the default device when starting the radio is the loopback, we can just create a new one and set frequencies and gains. Then run the WBFM receiver again and start receiving FM radio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Radio()\n",
    "R.freq_rx = 94100.0\n",
    "R.sdr_gain = 36\n",
    "# R.audiodev_out = \"plughw:CARD=Loopback,DEV=0\" # optional, since it is a default.\n",
    "R.WBFMrx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stream\n",
    "# will record from device \"loop1\" and play through device \"builtin\" \n",
    "st = sd.Stream(device=(loop1_idx, builtin_idx), callback=replay_callback)\n",
    "\n",
    "# start stream -- will run in background till stopped\n",
    "st.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop and close stream -- must stop and close for clean exit\n",
    "st.stop()\n",
    "st.close()\n",
    "R.stoprx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to change the volume of the audio by setting R.audio_rcv_gain, which can be any positive floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Radio()\n",
    "R.freq_rx = 94100.0\n",
    "R.sdr_gain = 36\n",
    "# R.audiodev_out = \"plughw:CARD=Loopback,DEV=0\" # optional, since it is a default.\n",
    "R.audio_rcv_gain = 0.1\n",
    "R.WBFMrx()\n",
    "\n",
    "# create stream\n",
    "# will record from device \"loop1\" and play through device \"builtin\"\n",
    "st = sd.Stream(device=(loop1_idx, builtin_idx), callback=replay_callback)\n",
    "\n",
    "# start stream -- will run in background till stopped\n",
    "st.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop and close stream -- must stop and close for clean exit\n",
    "st.stop()\n",
    "st.close()\n",
    "R.stoprx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following callback will do exactly the same thing as before. The only difference is that the received audio will be pushed to a Queue so we can process it outside of the callback function. Default block-size is 512 samples, which is about 10 ms worth of samples -- this seems to be a problem for the Pi. We will therefore use 1024 samples per block, which is about 20 ms worth of samples.\n",
    "\n",
    "We will capture just over 10 seconds, which is about 500 blocks. The samples from the queue will be processed. We will compute the maximum signal and the root-mean-square (RMS) for each block. This will let us see if the signal is being clipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queuereplay_callback(indata, outdata, frames, time, status):\n",
    "    assert frames == 1024\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    outdata[:] = indata # keep this only if you are not transmitting!\n",
    "    Qin.put( indata.copy() ) # global queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Radio()\n",
    "R.freq_rx = 94100.0\n",
    "R.sdr_gain = 36\n",
    "# R.audiodev_out = \"plughw:CARD=Loopback,DEV=0\" # optional, since it is a default.\n",
    "R.audio_rcv_gain = 1.5\n",
    "R.WBFMrx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an input FIFO queue\n",
    "Qin = Queue.Queue()\n",
    "\n",
    "st = sd.Stream(device=(loop1_idx, builtin_idx), blocksize=1024, callback=queuereplay_callback)\n",
    "\n",
    "st.start()\n",
    "\n",
    "# record and play about 10.6 seconds of audio 500*1024/48000 = 10.6 s\n",
    "mxpwr = zeros(500)\n",
    "rmspwr = zeros(500)\n",
    "\n",
    "for n in range(500):\n",
    "    samples = Qin.get()\n",
    "    mxpwr[n] = max(abs(samples))\n",
    "    rmspwr[n] = np.sqrt(np.sum(np.square(samples)))\n",
    "    # You can add code here to do processing on samples in chunks of 512 samples\n",
    "    # In general, you will have to implement an overlap and add, or overlap an save to get\n",
    "    # continuity between chunks -- we will do this later!\n",
    "\n",
    "st.stop()\n",
    "st.close()\n",
    "\n",
    "# empty queue just in case there's something left\n",
    "while not(Qin.empty()):\n",
    "    samples = Qin.get()\n",
    "R.stoprx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code also displays the RMS amplitude and maximum audio signal for each 1024-sample block -- so you can see if it is clipped or too weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "t = r_[0:500]*1024/48000\n",
    "plt.plot(t, mxpwr)\n",
    "plt.plot(t, rmspwr/np.sqrt(1024))\n",
    "plt.title('Maximum/RMS amplitude')\n",
    "plt.legend(('Max amplitude','RMS amplitude'))\n",
    "\n",
    "if any(mxpwr > 0.95):\n",
    "    print(\"Warning! Signal is clipped. Reduce radio volume, and/or usb device input volume.\")\n",
    "if max(mxpwr) < 0.3:\n",
    "    print(\"Audio volume may be too low. Increase the volume on the radio for better lab performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set the volume such that the peak is not higher than 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"radio\" is also able to demodulate narrow-band FM, such as Walkie Talkies, NOAA weather, and the Baofeng radio.\n",
    "Pick a local NOAA weather repeater frequency (162.400 MHz, 162.425 MHz, 162.450 MHz, 162.475 MHz, 162.500 MHz, 162.525 MHz, and 162.550 MHz), or if you have a Baofeng radio and a license, choose an amateur radio band (one of the experimental frequencies programmed on your radio) and test the receiver. Repeat the recording and amplitude experiment from above with narrowband FM. You can transmit while pressing on the keys to play DTMF tones.\n",
    "\n",
    "The code: ``R.NFMrx()`` starts a narrowband FM receiver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Radio()\n",
    "R.freq_rx = 162425.0\n",
    "R.sdr_gain = 36\n",
    "# R.audiodev_out = \"plughw:CARD=Loopback,DEV=0\" # optional, since it is a default.\n",
    "R.audio_rcv_gain = 1\n",
    "R.NFMrx()\n",
    "\n",
    "# create an input FIFO queue\n",
    "Qin = Queue.Queue()\n",
    "\n",
    "st = sd.Stream(device=(loop1_idx, builtin_idx), blocksize=1024, callback=queuereplay_callback)\n",
    "\n",
    "st.start()\n",
    "\n",
    "# record and play about 10.6 seconds of audio 500*1024/48000 = 10.6 s\n",
    "mxpwr = zeros(500)\n",
    "rmspwr = zeros(500)\n",
    "\n",
    "for n in range(500):\n",
    "    samples = Qin.get()\n",
    "    mxpwr[n] = max(abs(samples))\n",
    "    rmspwr[n] = np.sqrt(np.sum(np.square(samples)))\n",
    "    # You can add code here to do processing on samples in chunks of 512 samples\n",
    "    # In general, you will have to implement an overlap and add, or overlap an save to get\n",
    "    # continuity between chunks -- we will do this later!\n",
    "\n",
    "st.stop()\n",
    "st.close()\n",
    "\n",
    "# empty queue just in case there's something left\n",
    "while not(Qin.empty()):\n",
    "    samples = Qin.get()\n",
    "\n",
    "R.stoprx()\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "t = r_[0:500]*1024/48000\n",
    "plt.plot(t, mxpwr)\n",
    "plt.plot(t, rmspwr/np.sqrt(1024))\n",
    "plt.title('Maximum/RMS amplitude')\n",
    "plt.legend(('Max amplitude','RMS amplitude'))\n",
    "\n",
    "if any(mxpwr > 0.95):\n",
    "    print(\"Warning! Signal is clipped. Reduce radio volume, and/or usb device input volume.\")\n",
    "if max(mxpwr) < 0.3:\n",
    "    print(\"Audio volume may be too low. Increase the volume on the radio for better lab performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing radio transmission\n",
    "\n",
    "The next step is to test the transmission through RPiTX. \n",
    "If you have a Baofeng radio and for some reason you cannot do the \"interface\" (old) version of this lab, you can use it to listen to the transmission and validate that things are working. For this case, I recommennd using one of the UHF experimental channels 71-98 on your radio. \n",
    "\n",
    "If you do not have a radio, then I recommend using the unlicensed band 919 MHz. Do not connect any wire to GPIO 4 (pin 7), on the Pi, so that you do not violate any FCC rules.\n",
    "\n",
    "The basics for transmitting with RPiTX are similar to the receive, in term of configuration.\n",
    "\n",
    "The important variables are:\n",
    "~~~~\n",
    "Radio.freq_tx = transmit_freq \n",
    "Radio.audiodev_in=\"hw:CARD=ALSA,DEV=0\"\n",
    "Radio.NFMtx()\n",
    "Radio.stoptx() # or Radio.close()\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmitting audio from the Pi to the radio\n",
    "\n",
    "Below is code that:\n",
    "- transmits a 2 kHz tone for 2 seconds\n",
    "- pauses for a little while\n",
    "- transmits a 1 kHz tone for 2 seconds\n",
    "- receives the transmission and records it\n",
    "- plays back the recording\n",
    "\n",
    "Unfortunately, we cannot transmit, receive, and play at the same time. \n",
    "Instead, we will transmit RF via GPIO 4 (pin 7), receive with the SDR, and push the received audio to the loopback device. \n",
    "At the same time, we will use a streaming audio interface to read loopback samples and put in a Queue. \n",
    "After finishing the transmission and reception, we will terminate the transmit and play the sound from the Queue.\n",
    "\n",
    "Sounds good?\n",
    "\n",
    "Here's a callback function which only stores samples in a queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queuerecord_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    Qin.put( indata.copy() ) # global queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a receiver and start a stream for saving the receiver output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a receiver\n",
    "R = Radio()\n",
    "R.freq_rx = 919000.0\n",
    "R.sdr_gain = 50\n",
    "# R.audiodev_out = \"plughw:CARD=Loopback,DEV=0\" # optional, since it is a default.\n",
    "\n",
    "# start receiving\n",
    "R.NFMrx()\n",
    "\n",
    "# start the queue for receiving\n",
    "Qin = Queue.Queue()\n",
    "st = sd.InputStream(device=loop1_idx, blocksize=1024, callback=queuerecord_callback)\n",
    "st.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose transmission frequency:\n",
    "R.freq_tx = 919000.0\n",
    "\n",
    "# generate sinusoids\n",
    "fs_se = 48000 # audio sampling rate\n",
    "t = r_[0.0:fs_se*2]/fs_se\n",
    "sig1 = 0.5*sin(2*pi*2e3*t)\n",
    "sig2 = 0.5*sin(2*pi*1e3*t)\n",
    "\n",
    "R.NFMtx()\n",
    "time.sleep(0.1) # give radio time to start\n",
    "# play audio on the sound extension. When blocking is True, this will run in the foreground.\n",
    "sd.play(sig1, samplerate=fs_se, device=loop1_idx, blocking=True)\n",
    "\n",
    "R.stoptx()\n",
    "time.sleep(0.5)\n",
    "R.NFMtx()\n",
    "time.sleep(0.1) # give radio time to start\n",
    "sd.play(sig2, samplerate=fs_se, device=loop1_idx, blocking=True)\n",
    "\n",
    "R.close()\n",
    "st.stop()\n",
    "st.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble the received samples into a single array and play it on your speaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(Qin.empty()):\n",
    "    recorded_radio = Qin.get_nowait()\n",
    "while not(Qin.empty()):\n",
    "    recorded_radio = np.concatenate((recorded_radio, Qin.get_nowait()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(recorded_radio, samplerate=fs_se, device=builtin_idx, blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating the input audio level to the radio using radio transmission and reception with the SDR \n",
    "\n",
    "A few facts about handheld FM radios:\n",
    "\n",
    "In general, the audio input to the radio is filtered within the radio by a bandpass filter, which passes frequencies roughly between 500 Hz and 4 kHz. The input filter also emphasizes the high frequencies with approximately 6 dB per decade up to 3 kHz. This is because FM has higher noise in the high frequency, so by sending higher amplitude for high frequencies, the SNR remains the same for all frequencies.\n",
    "\n",
    "Another fact about FM is that the amount of frequency deviation is proportional to the amplitude of the audio. However, before transmitting, the modulated FM signal goes through a bandpass filter so that energy does not leak to other channels. If the input volume is too high, the output bandpass filter will \"crop\" the signal and the transmitted audio will be distorted. It is therefore important that we have a way to set the right level of output such that there's no clipping of the signal. \n",
    "\n",
    "In this task, we will transmit a pure audio tone with linearly increasing amplitude. We will receive the signal using the SDR and FM demodulate it (similarly to Lab 3). We will then determine the amplitude in which the signal is still \"well behaved\" -- not clipped and without non-linearities.\n",
    "\n",
    "Here's how it works with physical radios: \n",
    "* We generate a tone with increasing amplitude in python.\n",
    "* The audio interface converts it into an analog signal -- acting as a DAC.\n",
    "* The radio filters the input with its audio bandpass filter.\n",
    "* The radio FM modulates the signal with $\\pm7.5$ kHz deviation at the chosen center frequency and transmits the FM signal.\n",
    "\n",
    "Here's how we will simulate it with RPiTX:\n",
    "* We will generate a tone with increasing amplitude in python.\n",
    "* We will \"play\" the tone to the virtual loopback audio device, which will pass it to the RPiTX script.\n",
    "* RPiTX script will read the \"audio\" and use CSDR to perform digital bandpass filtering.\n",
    "* CSDR will then perform the FM modulation and provide RPiTX with the appropriate output.\n",
    "* RPiTX will transmit the signal at the chosen center frequency. \n",
    "\n",
    "Here's how the receiving will work:\n",
    "* The SDR will capture samples around that center frequency.\n",
    "* You will implement a carrier squelch that will crop the samples corresponding to the transmission.\n",
    "* You will FM demodulate the signal by implementing a lowpass filter, limiter, and discriminator similarly to Lab 3. \n",
    "* You will then look at the amplitude of the received tone. The amplitude should increase linearly at first, then taper off and saturate. You need to figure out which audio amplitude values are in the linear regime. The range of values you will get will correspond to the range of audio signals that will not be distorted using your audio settings!\n",
    "\n",
    "The latter part is only necessary when using a physical radio, where the gains of your Raspberry Pi and the input amplifier of the radio are not known. Here, any signal between 0-1.0 should be linear -- but to show the effect, we will drive it beyond. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Task:  Setting the gain of the SDR and calibrating the frequency\n",
    "\n",
    "It is important to know that even though we set a transmit and receive frequency, the frequency the radio is transmitting and the frequency the SDR is receiving may not be exactly the same. This is because the crystal oscillator on the Raspberry Pi is rated to about 1 ppm, and the SDR is rated to about 70 ppm deviation.  \n",
    "Before we start, we would like to make sure that the SDR frequency is calibrated to the radio (both may have some offset). We would also like to adjust the gain of the SDR, so it is not under/overdriven by the radio.\n",
    "\n",
    "For this, we will transmit a carrier at the center frequency of the radio and receive at the center frequency of the SDR. We will look at the spectrum to see the offset between the transmitted frequency and the received one. We will then calibrate the offset of the SDR with respect to the radio. The SDR has a parameter \"ppm\" for prescribing known frequency offsets.\n",
    "\n",
    "We will also look at the received amplitude to see if it's clipped.\n",
    "\n",
    "* Acquire 2 seconds of data while the radio is transmitting.\n",
    "* Plot the amplitude of the signal. Make sure the amplitude of the signal is > 0.25 and < 0.75. If not, change the gain of the SDR or move the receive antenna away from the radio.\n",
    "* Plot the average power spectrum or the spectrogram, and calculate the offset frequency. Find the approximate frequency offset in parts-per-millon (ppm).\n",
    "* Repeat the above until the magnitude of the signal is within range and its frequency is centered. \n",
    "* Record the SDR gain and the ppm shift. You will need to use it later.\n",
    "\n",
    "Use the frequency 919 MHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up SDR\n",
    "fs_sdr = 240000\n",
    "fc = ??? # set your frequency\n",
    "ppm = ??? # set your ppm! (Hint: start with 1)\n",
    "gain = ??? # set your SDR gain (Hint: 0 - 50)\n",
    "\n",
    "sdr = RtlSdr()\n",
    "sdr.sample_rate = fs_sdr\n",
    "sdr.gain = gain\n",
    "sdr.center_freq = fc\n",
    "sdr.freq_correction = ppm\n",
    "\n",
    "R = Radio()\n",
    "R.freq_tx = 919000\n",
    "\n",
    "# start transmitting\n",
    "R.NFMtx()\n",
    "time.sleep(0.5)\n",
    "y = sdr.read_samples(fs_sdr)\n",
    "\n",
    "# stop transmitting\n",
    "R.close()\n",
    "sdr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to plot amplitude and compute frequency here:\n",
    "\n",
    "\n",
    "# set correction values\n",
    "ppmcalib = int(ppm - np.round(f0/fc*1e6))\n",
    "gaincalib = gain\n",
    "\n",
    "print('shift in Hz:', f0)\n",
    "print('shift in ppm:', ppmcalib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the SDR frequency and gain are calibrated, let's do the calibration of the audio level to the radio.\n",
    "\n",
    "#### Task 1\n",
    "\n",
    "* Generate a 4 second tone at 2200 Hz. The tone amplitude should vary linearly from 0 to 2 throughout the 4 seconds.\n",
    "* Add 250 ms worth of zeros at the beginning of the array.\n",
    "* Transmit the signal using the radio and simultaneously receive for 5 seconds using the SDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the tone\n",
    "\n",
    "\n",
    "# set up SDR\n",
    "fs_sdr = 240000\n",
    "fc = 919.000e6 # set your frequency!\n",
    "\n",
    "sdr = RtlSdr()\n",
    "sdr.sample_rate = fs_sdr\n",
    "sdr.gain = gaincalib\n",
    "sdr.center_freq = fc\n",
    "sdr.set_freq_correction(ppmcalib)\n",
    "\n",
    "# start transmitting\n",
    "R.NFMtx()\n",
    "time.sleep(0.5)\n",
    "sd.play(sig, samplerate=fs_se, device=loop1_idx, blocking=False) # play samples to radio\n",
    "\n",
    "# read samples from SDR\n",
    "y = sdr.read_samples(fs_sdr*5)\n",
    "\n",
    "# stop transmitting when done\n",
    "R.close()\n",
    "sdr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "\n",
    "* Plot the magnitude of the received signal, and pick a threshold to crop the samples corresponding to the transmission. \n",
    "* Again, make sure the amplitude of the signal is > 0.25 and < 0.75. If not, change the gain or move the SDR antenna away from the radio.\n",
    "* Crop the signal to the transmission part -- make sure you have > 2 seconds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "\n",
    "* Plot the spectrogram. Make sure the signal is close to the center frequency. If not, adjust the frequency correction ppm accordingly. \n",
    "* Can you see the bandwidth increasing and then leveling? Why is that happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "\n",
    "tt, ff, xmf = myspectrogram_hann_ovlp(y_d, 256, fs_sdr, 0, dbf=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "* Lowpass filter with a bandwidth of 15 kHz.\n",
    "* Downsample by 10 to 24 kHz effective sampling rate.\n",
    "* FM demodulate using the approach in Lab 3.\n",
    "* Plot the spectrogram of the demodulated signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "\n",
    "tt, ff, xmf = myspectrogram_hann_ovlp(y_df, 256, fs_sdr/10, 0, dbf=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "\n",
    "To see envelope of the transmitted tone: \n",
    "* Create a narrow single-sideband bandpass filter by complex modulating a Hann window (`signal.hann`) of length 513 to a center frequency around 2200 Hz\n",
    "* Filter the demodulated signal and display its magnitude (use `mode='same'` to compensate for the filter delay).\n",
    "* You should see a linear ramp that starts tapering near the maximum and then becomes flat. Find the time in seconds it took from the beginning of the ramp until just before it starts to roll off. Divide that value by 2 and you've got yourself the maximum amplitude that results in a linear response!\n",
    "\n",
    "#### Save the value of the maximum amplitude that is linear! (HINT: for RPiTX, the linear regime should be 0-1, hence a linear ramp for 2 seconds and then roll off.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring the Frequency Response of the Radio's Bandpass Audio Filter\n",
    "\n",
    "As mentioned earlier, in traditional handheld radios, the audio input to the radio is filtered by a bandpass filter. They also emphasize the high frequencies with a filter of approximately 6 dB per decade. We simulate this by using CSDR to filter the audio before sending to RPiTX.\n",
    "\n",
    "If the filter is unknown, it is possible to estimate its frequency response by transmitting a known signal and measuring the result. Here, we  will use a chirp signal to estimate the magnitude frequency response. We will transmit with the RPiTX radio and receive using the SDR.\n",
    "\n",
    "#### Task 6\n",
    "\n",
    "* Generate a chirp from 20 Hz to 8 kHz over 2 seconds.\n",
    "* Transmit using the radio, and record using the SDR (for 3 seconds).\n",
    "* Crop based on amplitude, filter, decimate, and FM demodulate.\n",
    "* Plot the spectrogram and the magnitude frequency response of the result.\n",
    "\n",
    "#### IMPORTANT --  the ppm calibration only lasts for a while. Its results can vary significantly (I observed -20 ppm to 20 ppm). If you are having poor demodulation results, perform the calibration again before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genChirpPulse(Npulse, f0, f1, fs):\n",
    "    #     Function generates a complex chirp pulse\n",
    "    #     Inputs: Npulse - pulse length in samples\n",
    "    #             f0     - start frequency of chirp\n",
    "    #             f1     - end frequency of chirp\n",
    "    #             fs     - sampling frequency\n",
    "    \n",
    "    t1 = r_[0.0:Npulse]/fs\n",
    "    Tpulse = Npulse / fs\n",
    "    f_of_t = f0 + t1 / Tpulse * (f1 - f0)\n",
    "    phi_of_t = 2*pi * np.cumsum(f_of_t)/fs\n",
    "    pulse = np.exp(1j*phi_of_t)\n",
    "    return pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the signal\n",
    "\n",
    "\n",
    "# set up SDR\n",
    "\n",
    "\n",
    "# start transmitting\n",
    "\n",
    "\n",
    "# stop transmitting when done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample and demodulate the FM signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spectrogram and the average power spectrum \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of estimating a frequency response is to transmit white noise, which has uniform energy throughout the spectrum. Its name is derived from the fact that light with equal contributions from every visible frequency appears white (optics!!!!!).\n",
    "\n",
    "#### Task 7\n",
    "\n",
    "* Generate 4 seconds (at 48 kHz sampling rate) of white uniform noise between -1 and 1 using `np.random.rand`.\n",
    "* Scale the amplitude to the maximum linear amplitude value you found previously.\n",
    "* Transmit using the radio, and record using the SDR.\n",
    "* Crop based on amplitude, filter, decimate, and FM demodulate.\n",
    "* Plot the spectrogram.\n",
    "\n",
    "In order to display a non-noisy spectrum, we will need to compute an average power spectrum. Use the function `avgPS` to do so.\n",
    "\n",
    "* Use a window size of 128 and plot the square root of the result for the positive frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate the signal\n",
    "\n",
    "\n",
    "# set up SDR\n",
    "\n",
    "\n",
    "# start transmitting\n",
    "\n",
    "\n",
    "# stop transmitting when done\n",
    "\n",
    "\n",
    "# downsample and demodulate\n",
    "\n",
    "\n",
    "# plot spectrogram and average power spectrum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmitting your callsign in Morse code\n",
    "\n",
    "The next step is to see if you can transmit something more meaningful. If you are going to transmit for the first time using a computer, you might as well transmit your callsign in Morse code!\n",
    "\n",
    "Morse code is composed of dots (notated . and pronounced dit) and dashes (notated - and pronounced dah). The timing is relative to a dit duration which is one unit long. A dah is three units long. The gap between dots and dashes within a character is one unit. A short gap between letters is three units and a gap between words is seven units.\n",
    "\n",
    "A dictionary of Morse code is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "\n",
    "* Implement a function `sig = text2Morse(text, fc, fs,dt)`. The function will take a string and convert it to a tone signal of the Morse code of the text. The function will also take 'fc' the frequency of the tones (800-900 Hz sounds nice), 'fs' the sampling frequency, and 'dt' the Morse unit time (hence the speed, 50-75 ms recommended).\n",
    "* Transmit your call sign! You can use this function to identify yourself before, during, and after a transmission from now on.\n",
    "* Validate the code by capturing a spectrogram using the SDR.\n",
    "\n",
    "You can also play the sound of your recording!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2Morse(text,fc,fs,dt):\n",
    "    CODE = {'A': '.-',     'B': '-...',   'C': '-.-.', \n",
    "        'D': '-..',    'E': '.',      'F': '..-.',\n",
    "        'G': '--.',    'H': '....',   'I': '..',\n",
    "        'J': '.---',   'K': '-.-',    'L': '.-..',\n",
    "        'M': '--',     'N': '-.',     'O': '---',\n",
    "        'P': '.--.',   'Q': '--.-',   'R': '.-.',\n",
    "        'S': '...',    'T': '-',      'U': '..-',\n",
    "        'V': '...-',   'W': '.--',    'X': '-..-',\n",
    "        'Y': '-.--',   'Z': '--..',\n",
    "        \n",
    "        '0': '-----',  '1': '.----',  '2': '..---',\n",
    "        '3': '...--',  '4': '....-',  '5': '.....',\n",
    "        '6': '-....',  '7': '--...',  '8': '---..',\n",
    "        '9': '----.',\n",
    "\n",
    "        ' ': ' ', \"'\": '.----.', '(': '-.--.-',  ')': '-.--.-',\n",
    "        ',': '--..--', '-': '-....-', '.': '.-.-.-',\n",
    "        '/': '-..-.',   ':': '---...', ';': '-.-.-.',\n",
    "        '?': '..--..', '_': '..--.-'\n",
    "        }\n",
    "    \n",
    "    Ndit = np.int32(1.0*fs*dt)\n",
    "    Ndah = 3*Ndit\n",
    "    \n",
    "    sdit = np.sin(2*pi*fc*r_[0.0:Ndit]/fs)\n",
    "    sdah = np.sin(2*pi*fc*r_[0.0:Ndah]/fs)\n",
    "    \n",
    "    # convert to dit dah\n",
    "    mrs = \"\"\n",
    "    for char in text:\n",
    "        mrs = mrs + CODE[char.upper()] + \"*\"\n",
    "    \n",
    "    sig = zeros(1)\n",
    "    for char in mrs:\n",
    "        if char == \" \":\n",
    "            sig = np.concatenate((sig,zeros(Ndit*7)))\n",
    "        if char == \"*\":\n",
    "            sig = np.concatenate((sig,zeros(Ndit*3)))\n",
    "        if char == \".\":\n",
    "            sig = np.concatenate((sig,sdit,zeros(Ndit)))\n",
    "        if char == \"-\":\n",
    "            sig = np.concatenate((sig,sdah,zeros(Ndit)))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_sdr = 240000\n",
    "fc = 919.000e6\n",
    "\n",
    "sdr = RtlSdr()\n",
    "sdr.sample_rate = fs_sdr\n",
    "sdr.gain = gaincalib\n",
    "sdr.center_freq = fc\n",
    "sdr.set_freq_correction(ppmcalib)\n",
    "\n",
    "R = Radio()\n",
    "R.freq_tx = 919000\n",
    "\n",
    "fs_se = 48000\n",
    "callsign = text2Morse(YOUR CALLSIGN e.g. \"KN6IFE\", 850, fs_se, 75e-3)\n",
    "callsign = np.concatenate((np.zeros(fs_se//10),callsign))                    \n",
    "T = len(callsign) / fs_se # time to transmit\n",
    "\n",
    "R.NFMtx()\n",
    "time.sleep(0.1)\n",
    "sd.play(callsign, samplerate=fs_se, device=loop1_idx, blocking=False)\n",
    "\n",
    "y = sdr.read_samples(int(fs_sdr*(T+1)))\n",
    "\n",
    "sdr.close()\n",
    "R.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample and demodulate\n",
    "\n",
    "y_df = ???\n",
    "\n",
    "y_play = signal.resample( y_df/max(abs(y_df))*0.9, len(y_df)*2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(y_play, samplerate=fs_se, device=builtin_idx, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt, ff, xmf = myspectrogram_hann_ovlp(y_df, 256, fs_sdr/10, 0, dbf=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
